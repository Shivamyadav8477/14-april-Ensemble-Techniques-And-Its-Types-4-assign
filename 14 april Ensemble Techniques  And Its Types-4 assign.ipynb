{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0784ec3c-4f9b-4aee-a2bb-e3f3b3d00937",
   "metadata": {},
   "outputs": [],
   "source": [
    "Build a random forest classifier to predict the risk of heart disease based on a dataset of patient\n",
    "information. The dataset contains 303 instances with 14 features, including age, sex, chest pain type,\n",
    "resting blood pressure, serum cholesterol, and maximum heart rate achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163bbe09-62f7-495f-b888-7233590d31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Preprocess the dataset by handling missing values, encoding categorical variables, and scaling the\n",
    "numerical features if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c66a9d-8a2e-4c54-9d58-854a0440df22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55633d1c-0089-4cc7-a777-13cf1de1ff86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc58fd3-b312-450d-b237-93e1a4a53195",
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessing a dataset typically involves handling missing values, encoding categorical variables, and scaling numerical features if needed. Here's a step-by-step guide on how to perform these preprocessing steps:\n",
    "\n",
    "Handling Missing Values:\n",
    "\n",
    "Identify Missing Values: Start by identifying which columns in your dataset have missing values.\n",
    "\n",
    "Impute Missing Values: Decide on a strategy to fill in missing values based on the nature of the data:\n",
    "\n",
    "For numerical features, you can impute missing values with the mean, median, or mode of the respective feature.\n",
    "For categorical features, you can impute missing values with the most frequent category or use a special category like \"Unknown.\"\n",
    "Pandas Example (Assuming 'df' is your DataFrame):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd73906-7250-4068-a367-38bb44481392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for numerical columns with the mean\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Impute missing values for categorical columns with the most frequent category\n",
    "df.fillna(df.mode().iloc[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe03099-d6d6-435b-b72c-8ca6b0030730",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoding Categorical Variables:\n",
    "\n",
    "Label Encoding: For ordinal categorical variables (categories with an inherent order), you can use label encoding to convert categories into numerical values. Use the LabelEncoder from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92dd6a-169d-4305-a146-7a026362c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['ordinal_categorical_column'] = label_encoder.fit_transform(df['ordinal_categorical_column'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0069e39-31d6-491c-a933-bd4bc852800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "One-Hot Encoding: For nominal categorical variables (categories without an inherent order), use one-hot encoding to create binary columns for each category. Use the pd.get_dummies function in pandas or the OneHotEncoder from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725efa1-0e53-4124-9595-4e4d3a20f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas\n",
    "df = pd.get_dummies(df, columns=['nominal_categorical_column'])\n",
    "\n",
    "# Using scikit-learn (if needed)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded_cols = encoder.fit_transform(df[['nominal_categorical_column']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef04072-5b78-44f1-b53e-d7c6ee1c4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaling Numerical Features (if necessary):\n",
    "\n",
    "Feature Scaling: Scaling numerical features can be important for algorithms that are sensitive to the scale of the input features, such as gradient descent-based methods. Common scaling techniques include Min-Max scaling and Standardization (z-score scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cdad88-c04f-4483-922b-644a629a801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "df[['numerical_feature1', 'numerical_feature2']] = scaler.fit_transform(df[['numerical_feature1', 'numerical_feature2']])\n",
    "\n",
    "# Standardization (z-score scaling)\n",
    "scaler = StandardScaler()\n",
    "df[['numerical_feature1', 'numerical_feature2']] = scaler.fit_transform(df[['numerical_feature1', 'numerical_feature2']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d41d4-ab43-4ea1-b422-d3b3277f6d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final Data Inspection: After preprocessing, it's essential to inspect your dataset to ensure that missing values are handled, categorical variables are encoded properly, and numerical features are scaled if necessary. Additionally, check for any outliers or anomalies in the data.\n",
    "\n",
    "Remember that the specific preprocessing steps may vary depending on the nature of your dataset and the machine learning algorithm you plan to use. It's crucial to understand your data and choose the appropriate preprocessing techniques accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aa913f-b73a-47f4-a57a-37ceece9e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Split the dataset into a training set (70%) and a test set (30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b88d9e-8152-4c8e-8ac0-473d356fcc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Splitting a dataset into a training set and a test set is a fundamental step in machine learning to evaluate the model's performance on unseen data. You can use various libraries in Python, such as scikit-learn, to perform this data split. Below is a step-by-step guide using scikit-learn:\n",
    "\n",
    "Assuming you have a DataFrame df with your dataset and a target variable target_column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188de6b-c692-450a-a77a-8dfa19408c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into features (X) and the target variable (y)\n",
    "X = df.drop(columns=['target_column'])\n",
    "y = df['target_column']\n",
    "\n",
    "# Split the data into a training set (70%) and a test set (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# \"test_size\" parameter specifies the proportion of the dataset to include in the test split.\n",
    "# \"random_state\" ensures reproducibility; you can use any integer value or leave it out for randomness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d018a8-9ff4-44b8-96aa-d8c9421a66ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "After running this code, you will have:\n",
    "\n",
    "X_train: The feature data (70%) for training your machine learning model.\n",
    "X_test: The feature data (30%) for evaluating your model's performance.\n",
    "y_train: The corresponding target values (70%) for training.\n",
    "y_test: The corresponding target values (30%) for testing.\n",
    "You can now use X_train and y_train to train your machine learning model and X_test to evaluate its performance. Make sure not to use the test set for model training to ensure that your model's performance assessment is unbiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44945852-6735-43ea-9b13-be84487f4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "To train a Random Forest Classifier using scikit-learn with 100 trees and a maximum depth of 10 for each tree, you can follow these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e5d56-36b2-41c1-8cf4-608315aea60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the Random Forest Classifier with 100 trees and a maximum depth of 10 for each tree\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "rf_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2339d9-a0ba-4520-8ff5-ae25e9af5351",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here's a breakdown of what this code does:\n",
    "\n",
    "Import the RandomForestClassifier class from scikit-learn's ensemble module.\n",
    "\n",
    "Create an instance of the Random Forest Classifier with the specified hyperparameters:\n",
    "\n",
    "n_estimators: This parameter specifies the number of trees in the forest, which is set to 100.\n",
    "max_depth: It sets the maximum depth of each decision tree to 10.\n",
    "Initialize the random state with random_state=42 for reproducibility.\n",
    "\n",
    "Fit (train) the Random Forest Classifier on the training set (X_train and y_train) using the .fit() method.\n",
    "\n",
    "Now, your rf_classifier is trained and ready to make predictions on new data or be evaluated on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242f876-fc15-4ceb-bca1-bb4cc62c8990",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Evaluate the performance of the model on the test set using accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362083b-23a0-4043-a064-a32853559190",
   "metadata": {},
   "outputs": [],
   "source": [
    "To evaluate the performance of your Random Forest Classifier on the test set using accuracy, precision, recall, and F1 score, you can follow these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c5f48-33e6-4d43-a2fa-1fc034bd1ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd8037-fe2c-48a4-ba30-1e605c4f51d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here's what this code does:\n",
    "\n",
    "Import the necessary evaluation metrics from scikit-learn (accuracy_score, precision_score, recall_score, f1_score).\n",
    "\n",
    "Use the trained Random Forest Classifier (rf_classifier) to make predictions on the test set (X_test) by calling the .predict() method.\n",
    "\n",
    "Calculate the accuracy, precision, recall, and F1 score by comparing the predicted labels (y_pred) with the true labels (y_test) using the respective metric functions.\n",
    "\n",
    "Print the evaluation metrics to the console.\n",
    "\n",
    "Running this code will provide you with the accuracy, precision, recall, and F1 score, which are common metrics used to assess the performance of a classification model on a test dataset. These metrics provide insights into different aspects of model performance:\n",
    "\n",
    "Accuracy: Measures the overall correctness of predictions.\n",
    "Precision: Measures the ratio of correctly predicted positive instances to the total predicted positive instances.\n",
    "Recall: Measures the ratio of correctly predicted positive instances to the total actual positive instances.\n",
    "F1 Score: Combines precision and recall into a single metric, useful when dealing with imbalanced datasets.\n",
    "These metrics collectively give you a good understanding of how well your Random Forest Classifier is performing on the test data.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4426a5f-ab7d-4471-afa0-4bc7519ab557",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Use the feature importance scores to identify the top 5 most important features in predicting heart\n",
    "disease risk. Visualise the feature importances using a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81b1fa-cee9-49b3-9999-c765d5a92cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "To identify the top 5 most important features in predicting heart disease risk using the feature importance scores from your Random Forest Classifier and visualize them with a bar chart, you can follow these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc13c01-f576-4dc2-aa50-e60533b49fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get feature importances from the trained Random Forest Classifier\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Get the names of the features (column names)\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame to organize feature names and their importances\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select the top 5 most important features\n",
    "top_features = importance_df.head(5)\n",
    "\n",
    "# Create a bar chart to visualize the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 5 Most Important Features for Heart Disease Prediction')\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis to display the most important feature at the top\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c850a-7b19-4395-8518-20865b2dbe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here's a breakdown of what this code does:\n",
    "\n",
    "Import the necessary libraries, including matplotlib.pyplot for visualization and numpy for numerical operations.\n",
    "\n",
    "Retrieve the feature importances from the trained Random Forest Classifier using the .feature_importances_ attribute.\n",
    "\n",
    "Obtain the names of the features (column names) from the training data.\n",
    "\n",
    "Create a DataFrame (importance_df) to organize the feature names and their corresponding importances.\n",
    "\n",
    "Sort the DataFrame by importance in descending order to identify the most important features.\n",
    "\n",
    "Select the top 5 most important features from the sorted DataFrame.\n",
    "\n",
    "Create a horizontal bar chart using matplotlib to visualize the feature importances. The plt.barh() function is used to create the horizontal bar chart, and plt.gca().invert_yaxis() is used to display the most important feature at the top of the chart.\n",
    "\n",
    "Running this code will generate a bar chart that visually represents the top 5 most important features for predicting heart disease risk based on the Random Forest Classifier's feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bedb940-655a-44b8-85c3-0074e9973c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Tune the hyperparameters of the random forest classifier using grid search or random search. Try\n",
    "different values of the number of trees, maximum depth, minimum samples split, and minimum samples\n",
    "leaf. Use 5-fold cross-validation to evaluate the performance of each set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17969357-84b0-4543-a8dd-8354946188c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuning the hyperparameters of a Random Forest Classifier using either grid search or random search with cross-validation is a common approach to finding the best combination of hyperparameters for your model. Here, I'll demonstrate how to perform hyperparameter tuning using grid search with 5-fold cross-validation as an example. You can modify it for random search if desired.\n",
    "\n",
    "First, make sure you have imported the necessary libraries and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05ce0e-50e8-412a-9bc7-6d3e8be1e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Different values for the number of trees\n",
    "    'max_depth': [10, 20, 30],       # Different values for maximum depth\n",
    "    'min_samples_split': [2, 5, 10],  # Different values for minimum samples to split\n",
    "    'min_samples_leaf': [1, 2, 4]     # Different values for minimum samples per leaf\n",
    "}\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found by grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the performance of the best model using cross-validation\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "cv_scores = cross_val_score(best_rf_classifier, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5b8fa-5785-4734-8855-3502a304e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "Define a grid of hyperparameter values to search through using param_grid. You specify different values for the number of trees (n_estimators), maximum depth (max_depth), minimum samples required to split a node (min_samples_split), and minimum samples required per leaf node (min_samples_leaf).\n",
    "\n",
    "Create a Random Forest Classifier (rf_classifier) with a fixed random state for reproducibility.\n",
    "\n",
    "Use GridSearchCV to perform a grid search with 5-fold cross-validation. The cv parameter specifies the number of folds for cross-validation, and scoring is set to 'accuracy' to evaluate the models based on accuracy.\n",
    "\n",
    "Fit the grid search to the training data (X_train and y_train) to find the best combination of hyperparameters.\n",
    "\n",
    "Print the best hyperparameters found by grid search.\n",
    "\n",
    "Retrieve the best estimator (Random Forest Classifier with the best hyperparameters) and evaluate its performance using cross-validation. Cross-validation scores are printed to assess model accuracy.\n",
    "\n",
    "You can adjust the param_grid and scoring metric as needed to explore different hyperparameter combinations and evaluation metrics during the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873747d-ed12-4d82-ac22-8e6c1f4f6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Report the best set of hyperparameters found by the search and the corresponding performance\n",
    "metrics. Compare the performance of the tuned model with the default model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d5b6db-7142-49e5-9744-bb259f60cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "To report the best set of hyperparameters found by the grid search and the corresponding performance metrics, and to compare the performance of the tuned model with the default model, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4810aa22-c3a8-4e83-a42e-3c62a2a657fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Best hyperparameters found by grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create a Random Forest Classifier with the best hyperparameters\n",
    "best_rf_classifier = RandomForestClassifier(random_state=42, **best_params)\n",
    "\n",
    "# Fit the best model to the training data\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_best = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "precision_best = precision_score(y_test, y_pred_best)\n",
    "recall_best = recall_score(y_test, y_pred_best)\n",
    "f1_score_best = f1_score(y_test, y_pred_best)\n",
    "\n",
    "# Performance metrics for the default model\n",
    "y_pred_default = rf_classifier.predict(X_test)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "precision_default = precision_score(y_test, y_pred_default)\n",
    "recall_default = recall_score(y_test, y_pred_default)\n",
    "f1_score_default = f1_score(y_test, y_pred_default)\n",
    "\n",
    "# Print the best hyperparameters and performance metrics\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Performance Metrics for the Best Model:\")\n",
    "print(f\"Accuracy: {accuracy_best:.2f}\")\n",
    "print(f\"Precision: {precision_best:.2f}\")\n",
    "print(f\"Recall: {recall_best:.2f}\")\n",
    "print(f\"F1 Score: {f1_score_best:.2f}\")\n",
    "\n",
    "# Compare performance with the default model\n",
    "print(\"\\nPerformance Metrics for the Default Model:\")\n",
    "print(f\"Accuracy: {accuracy_default:.2f}\")\n",
    "print(f\"Precision: {precision_default:.2f}\")\n",
    "print(f\"Recall: {recall_default:.2f}\")\n",
    "print(f\"F1 Score: {f1_score_default:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fdb808-36cd-4d46-8d80-f56026b08fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "We first retrieve the best hyperparameters found by the grid search using grid_search.best_params_.\n",
    "\n",
    "Then, we create a Random Forest Classifier (best_rf_classifier) with the best hyperparameters.\n",
    "\n",
    "We fit the best model to the training data and make predictions on the test set.\n",
    "\n",
    "We calculate performance metrics (accuracy, precision, recall, and F1 score) for both the best model (best_rf_classifier) and the default model (rf_classifier).\n",
    "\n",
    "Finally, we print the best hyperparameters and the performance metrics for both models to compare their performance.\n",
    "\n",
    "This allows you to assess how the tuned model with the best hyperparameters performs compared to the default model. You can evaluate whether the hyperparameter tuning process has resulted in improved model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f33b562-7414-4fe3-9279-8f9a0fbd34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Interpret the model by analysing the decision boundaries of the random forest classifier. Plot the\n",
    "decision boundaries on a scatter plot of two of the most important features. Discuss the insights and\n",
    "limitations of the model for predicting heart disease risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63bde43-a1c6-4098-9d3a-00c6e5d99a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interpreting the decision boundaries of a Random Forest Classifier can provide insights into how the model makes predictions. However, plotting the decision boundaries for a Random Forest, which is an ensemble of decision trees, can be challenging due to the complexity of the model. In practice, it's often more common to visualize decision boundaries for simple models like logistic regression or decision trees. Nevertheless, I'll provide some general guidance on how you can analyze and interpret a Random Forest Classifier.\n",
    "\n",
    "To visualize decision boundaries for a Random Forest Classifier, we'll simplify the task by selecting two of the most important features and using them to create a scatter plot. Keep in mind that this is a simplified representation and may not fully capture the complexity of the Random Forest's decision boundaries.\n",
    "\n",
    "Here's a step-by-step guide:\n",
    "\n",
    "Identify the Two Most Important Features: You can refer to the feature importances obtained from the Random Forest Classifier to determine the two most important features.\n",
    "\n",
    "Create a Scatter Plot: Select two features and create a scatter plot using these features as the x-axis and y-axis. You can use matplotlib for this.\n",
    "\n",
    "Generate Decision Boundaries: Since Random Forest is an ensemble of decision trees, it's challenging to directly visualize its decision boundaries. One approach is to use a mesh grid of points that cover the feature space and classify each point using the Random Forest. Then, plot the decision regions as contours or color regions.\n",
    "\n",
    "Here's some example code to get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b70064e-e067-4350-9fb0-67243f9b5c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the two most important features (replace with actual feature names)\n",
    "feature1 = 'Feature1'\n",
    "feature2 = 'Feature2'\n",
    "\n",
    "# Extract the corresponding columns from the dataset\n",
    "X_selected = X_train[[feature1, feature2]]\n",
    "\n",
    "# Fit the Random Forest Classifier to the selected features\n",
    "rf_classifier.fit(X_selected, y_train)\n",
    "\n",
    "# Create a mesh grid of points\n",
    "x_min, x_max = X_selected[feature1].min() - 1, X_selected[feature1].max() + 1\n",
    "y_min, y_max = X_selected[feature2].min() - 1, X_selected[feature2].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "# Predict the class labels for each point in the mesh grid\n",
    "Z = rf_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundaries as contour lines\n",
    "plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "\n",
    "# Scatter plot of the data points\n",
    "plt.scatter(X_selected[feature1], X_selected[feature2], c=y_train, cmap=plt.cm.RdYlBu)\n",
    "plt.xlabel(feature1)\n",
    "plt.ylabel(feature2)\n",
    "plt.title(\"Random Forest Classifier Decision Boundaries\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78904761-2b71-44c6-806e-220d54fd048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interpreting the insights and limitations:\n",
    "\n",
    "Insights: The decision boundaries in the scatter plot illustrate how the Random Forest Classifier separates different classes based on the selected features. You can observe regions where the model assigns different class labels. It provides a visual representation of the model's predictions in this simplified feature space.\n",
    "\n",
    "Limitations: Keep in mind that this visualization simplifies the model's decision boundaries, which are inherently complex and may involve interactions between numerous features. Random Forests are powerful ensemble models, but they can be challenging to interpret directly. This visualization only captures a two-dimensional projection of the model's behavior. Understanding the full scope of the model's decision-making may require more advanced techniques such as partial dependence plots or SHAP (SHapley Additive exPlanations) values for feature importance and interpretation.\n",
    "\n",
    "Interpreting Random Forest models often involves more than just visualizing decision boundaries. Additional techniques, such as feature importance analysis and model-agnostic interpretation methods, can provide deeper insights into how the model makes predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
